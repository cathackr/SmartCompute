#!/usr/bin/env python3
"""
SmartCompute MLE-STAR Integration
=================================

IntegraciÃ³n completa de MLE-STAR con la infraestructura existente de SmartCompute:
- Servidor Central MCP
- Cliente MCP unificado
- Dashboard de gestiÃ³n de incidentes
- Sistema HRM existente
- Monitoreo industrial
- AnÃ¡lisis enterprise

Esta integraciÃ³n permite que MLE-STAR colabore con HRM para:
1. Resolver incidentes con mayor precisiÃ³n
2. Mejorar la eficiencia operacional
3. Actualizar capacidades automÃ¡ticamente
4. Evolucionar el sistema de detecciÃ³n
5. Optimizar recursos computacionales
"""

import asyncio
import json
import logging
import time
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Union
from dataclasses import dataclass, asdict
from pathlib import Path
import sys

# Agregar directorios al path
sys.path.append('/home/gatux/smartcompute')
sys.path.append('/home/gatux/smartcompute/enterprise')

# Importar componentes existentes
try:
    from smartcompute_central_server import SmartComputeCentralServer
    from smartcompute_mcp_client import SmartComputeMCPClient
    from incident_management_dashboard import IncidentManagementDashboard
    from smartcompute_industrial_monitor import IndustrialSystemMonitor
    from generate_industrial_html_reports import IndustrialReportGenerator
except ImportError as e:
    logging.warning(f"Could not import SmartCompute components: {e}")

# Importar componentes MLE-STAR
try:
    from enterprise.mle_star_engine import MLESTAREngine, MLEAnalysisResult
    from enterprise.hrm_mle_collaborative_bridge import HRMMLECollaborativeBridge
    from enterprise.adaptive_capability_evolution import AdaptiveCapabilityEvolution
except ImportError as e:
    logging.warning(f"Could not import MLE-STAR components: {e}")

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class IntegrationConfig:
    """ConfiguraciÃ³n de integraciÃ³n MLE-STAR"""
    mle_star_enabled: bool = True
    hrm_collaboration_enabled: bool = True
    capability_evolution_enabled: bool = True
    real_time_analysis: bool = True
    auto_incident_creation: bool = True
    performance_optimization: bool = True
    resource_monitoring: bool = True
    backup_integration: bool = True

@dataclass
class SystemMetrics:
    """MÃ©tricas del sistema integrado"""
    timestamp: str
    mle_star_status: str
    hrm_bridge_status: str
    evolution_system_status: str
    total_analyses: int
    active_collaborations: int
    capability_improvements: int
    system_performance_score: float
    resource_utilization: Dict[str, float]

class SmartComputeMLESTARIntegration:
    """IntegraciÃ³n principal de MLE-STAR con SmartCompute"""

    def __init__(self, config_path: str = "/etc/smartcompute/mle-star-integration.yaml"):
        self.config = self._load_config(config_path)
        self.integration_config = IntegrationConfig()

        # Componentes del sistema
        self.central_server = None
        self.mcp_client = None
        self.dashboard = None
        self.industrial_monitor = None

        # Componentes MLE-STAR
        self.mle_engine = None
        self.hrm_bridge = None
        self.evolution_system = None

        # Estado de integraciÃ³n
        self.integration_status = "initializing"
        self.performance_metrics = {}
        self.active_integrations = {}

        # Conectores de datos
        self.data_connectors = {}
        self.analysis_queue = asyncio.Queue(maxsize=1000)
        self.incident_queue = asyncio.Queue(maxsize=500)

        logger.info("SmartCompute MLE-STAR Integration inicializando...")

    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """Cargar configuraciÃ³n de integraciÃ³n"""
        default_config = {
            'central_server_endpoint': 'https://localhost:8443',
            'dashboard_endpoint': 'http://localhost:8081',
            'industrial_monitor_enabled': True,
            'enterprise_analysis_enabled': True,
            'mle_star_analysis_interval': 60,  # segundos
            'hrm_sync_interval': 30,  # segundos
            'capability_evolution_interval': 1800,  # 30 minutos
            'integration_timeout': 300,  # 5 minutos
            'max_concurrent_analyses': 10,
            'performance_monitoring_enabled': True,
            'backup_mle_results': True,
            'real_time_dashboard_updates': True
        }

        try:
            import yaml
            with open(config_path, 'r') as f:
                user_config = yaml.safe_load(f)
            default_config.update(user_config)
        except FileNotFoundError:
            logger.warning(f"Config file {config_path} not found, using defaults")

        return default_config

    async def initialize_integration(self):
        """Inicializar integraciÃ³n completa"""
        try:
            logger.info("Iniciando integraciÃ³n MLE-STAR con SmartCompute...")

            # Paso 1: Inicializar componentes existentes de SmartCompute
            await self._initialize_smartcompute_components()

            # Paso 2: Inicializar componentes MLE-STAR
            await self._initialize_mle_star_components()

            # Paso 3: Establecer conectores de datos
            await self._setup_data_connectors()

            # Paso 4: Configurar flujos de trabajo integrados
            await self._setup_integrated_workflows()

            # Paso 5: Iniciar monitoreo y procesamiento
            await self._start_integration_monitoring()

            self.integration_status = "active"
            logger.info("IntegraciÃ³n MLE-STAR completada exitosamente")

        except Exception as e:
            logger.error(f"Error en integraciÃ³n MLE-STAR: {e}")
            self.integration_status = "failed"
            raise

    async def _initialize_smartcompute_components(self):
        """Inicializar componentes existentes de SmartCompute"""
        try:
            # Verificar si el servidor central estÃ¡ disponible
            import aiohttp
            async with aiohttp.ClientSession() as session:
                try:
                    async with session.get(
                        f"{self.config['central_server_endpoint']}/health",
                        timeout=10
                    ) as response:
                        if response.status == 200:
                            logger.info("Servidor central SmartCompute detectado")
                        else:
                            logger.warning("Servidor central no disponible, continuando sin Ã©l")
                except Exception:
                    logger.warning("No se pudo conectar al servidor central")

            # Inicializar componentes segÃºn disponibilidad
            if self.config.get('industrial_monitor_enabled', True):
                try:
                    self.industrial_monitor = IndustrialSystemMonitor()
                    logger.info("Monitor industrial inicializado")
                except Exception as e:
                    logger.warning(f"No se pudo inicializar monitor industrial: {e}")

            # Configurar cliente MCP si estÃ¡ disponible
            try:
                self.mcp_client = SmartComputeMCPClient()
                logger.info("Cliente MCP configurado")
            except Exception as e:
                logger.warning(f"No se pudo configurar cliente MCP: {e}")

        except Exception as e:
            logger.error(f"Error inicializando componentes SmartCompute: {e}")

    async def _initialize_mle_star_components(self):
        """Inicializar componentes MLE-STAR"""
        try:
            # Inicializar motor MLE-STAR
            self.mle_engine = MLESTAREngine()
            logger.info("Motor MLE-STAR inicializado")

            # Inicializar puente colaborativo HRM-MLE
            if self.integration_config.hrm_collaboration_enabled:
                self.hrm_bridge = HRMMLECollaborativeBridge()
                await self.hrm_bridge.initialize_systems()
                logger.info("Puente colaborativo HRM-MLE inicializado")

            # Inicializar sistema de evoluciÃ³n de capacidades
            if self.integration_config.capability_evolution_enabled:
                self.evolution_system = AdaptiveCapabilityEvolution()
                await self.evolution_system.initialize(self.mle_engine, self.hrm_bridge)
                logger.info("Sistema de evoluciÃ³n de capacidades inicializado")

        except Exception as e:
            logger.error(f"Error inicializando componentes MLE-STAR: {e}")
            raise

    async def _setup_data_connectors(self):
        """Configurar conectores de datos entre sistemas"""
        try:
            # Conector para anÃ¡lisis enterprise
            self.data_connectors['enterprise'] = EnterpriseDataConnector(
                self.mle_engine, self.hrm_bridge
            )

            # Conector para anÃ¡lisis industrial
            if self.industrial_monitor:
                self.data_connectors['industrial'] = IndustrialDataConnector(
                    self.industrial_monitor, self.mle_engine
                )

            # Conector para servidor central
            if self.mcp_client:
                self.data_connectors['central'] = CentralServerConnector(
                    self.mcp_client, self.mle_engine, self.hrm_bridge
                )

            logger.info(f"Configurados {len(self.data_connectors)} conectores de datos")

        except Exception as e:
            logger.error(f"Error configurando conectores de datos: {e}")

    async def _setup_integrated_workflows(self):
        """Configurar flujos de trabajo integrados"""
        try:
            # Flujo de trabajo: AnÃ¡lisis de amenazas integrado
            asyncio.create_task(self._integrated_threat_analysis_workflow())

            # Flujo de trabajo: GestiÃ³n de incidentes colaborativa
            asyncio.create_task(self._collaborative_incident_management_workflow())

            # Flujo de trabajo: EvoluciÃ³n de capacidades
            if self.evolution_system:
                asyncio.create_task(self._capability_evolution_workflow())

            # Flujo de trabajo: SincronizaciÃ³n de datos
            asyncio.create_task(self._data_synchronization_workflow())

            logger.info("Flujos de trabajo integrados configurados")

        except Exception as e:
            logger.error(f"Error configurando flujos de trabajo: {e}")

    async def _start_integration_monitoring(self):
        """Iniciar monitoreo de integraciÃ³n"""
        try:
            # Monitor de rendimiento
            asyncio.create_task(self._performance_monitoring_loop())

            # Monitor de salud del sistema
            asyncio.create_task(self._system_health_monitoring_loop())

            # Procesador de colas
            asyncio.create_task(self._queue_processing_loop())

            logger.info("Monitoreo de integraciÃ³n iniciado")

        except Exception as e:
            logger.error(f"Error iniciando monitoreo: {e}")

    async def _integrated_threat_analysis_workflow(self):
        """Flujo de trabajo de anÃ¡lisis de amenazas integrado"""
        while True:
            try:
                if not self.analysis_queue.empty():
                    analysis_request = await self.analysis_queue.get()
                    await self._process_integrated_analysis(analysis_request)

                await asyncio.sleep(1)

            except Exception as e:
                logger.error(f"Error en flujo de anÃ¡lisis integrado: {e}")
                await asyncio.sleep(5)

    async def _process_integrated_analysis(self, request: Dict[str, Any]):
        """Procesar anÃ¡lisis integrado MLE-STAR + HRM"""
        try:
            start_time = datetime.now()
            request_id = request.get('request_id', f"REQ-{start_time.strftime('%Y%m%d_%H%M%S')}")

            logger.info(f"Procesando anÃ¡lisis integrado: {request_id}")

            # AnÃ¡lisis MLE-STAR
            mle_result = await self.mle_engine.analyze_threat_data(request['data'])

            # ColaboraciÃ³n con HRM si estÃ¡ habilitada
            if self.hrm_bridge and self.integration_config.hrm_collaboration_enabled:
                hrm_context = request.get('hrm_context', {})
                collaboration_result = await self.hrm_bridge.collaborative_threat_analysis(
                    request['data'], hrm_context
                )

                # Fusionar resultados
                integrated_result = self._merge_analysis_results(mle_result, collaboration_result)
            else:
                integrated_result = {
                    'mle_analysis': asdict(mle_result),
                    'collaboration_result': None,
                    'fusion_applied': False
                }

            # Crear incidentes automÃ¡ticamente si estÃ¡ configurado
            if self.integration_config.auto_incident_creation:
                await self._auto_create_incidents(integrated_result)

            # Actualizar dashboard en tiempo real
            if self.config.get('real_time_dashboard_updates', True):
                await self._update_dashboard_real_time(integrated_result)

            # Registrar mÃ©tricas de rendimiento
            processing_time = (datetime.now() - start_time).total_seconds()
            await self._record_analysis_metrics(request_id, processing_time, integrated_result)

            logger.info(f"AnÃ¡lisis integrado completado: {request_id} en {processing_time:.2f}s")

        except Exception as e:
            logger.error(f"Error procesando anÃ¡lisis integrado: {e}")

    def _merge_analysis_results(
        self,
        mle_result: MLEAnalysisResult,
        collaboration_result: Any
    ) -> Dict[str, Any]:
        """Fusionar resultados de anÃ¡lisis MLE y colaboraciÃ³n HRM"""
        try:
            merged_result = {
                'analysis_id': f"MERGED-{mle_result.analysis_id}",
                'timestamp': datetime.now().isoformat(),
                'mle_analysis': asdict(mle_result),
                'collaboration_data': asdict(collaboration_result) if collaboration_result else None,
                'fusion_applied': True,
                'integrated_insights': {}
            }

            if collaboration_result and collaboration_result.success:
                # Combinar inteligencia fusionada
                fused_intel = collaboration_result.fused_intelligence

                merged_result['integrated_insights'] = {
                    'combined_risk_score': fused_intel.get('combined_insights', {}).get('risk_score', mle_result.risk_score),
                    'enhanced_confidence': fused_intel.get('combined_insights', {}).get('confidence_level', mle_result.confidence_level),
                    'threat_signatures_count': len(mle_result.threat_signatures),
                    'fusion_quality': fused_intel.get('fusion_quality', 0.0),
                    'hrm_contribution_score': collaboration_result.performance_impact.get('confidence_enhancement', 0.0),
                    'false_positive_reduction': collaboration_result.performance_impact.get('false_positive_reduction', 0.0)
                }

                # Combinar recomendaciones
                combined_recommendations = list(set(
                    mle_result.recommended_actions + collaboration_result.recommendations
                ))
                merged_result['integrated_insights']['recommendations'] = combined_recommendations[:15]

            else:
                # Solo usar resultados MLE
                merged_result['integrated_insights'] = {
                    'combined_risk_score': mle_result.risk_score,
                    'enhanced_confidence': mle_result.confidence_level,
                    'threat_signatures_count': len(mle_result.threat_signatures),
                    'fusion_quality': 0.0,
                    'recommendations': mle_result.recommended_actions[:10]
                }

            return merged_result

        except Exception as e:
            logger.error(f"Error fusionando resultados de anÃ¡lisis: {e}")
            return {
                'analysis_id': f"ERROR-{mle_result.analysis_id}",
                'timestamp': datetime.now().isoformat(),
                'mle_analysis': asdict(mle_result),
                'fusion_applied': False,
                'error': str(e)
            }

    async def _auto_create_incidents(self, analysis_result: Dict[str, Any]):
        """Crear incidentes automÃ¡ticamente basado en anÃ¡lisis"""
        try:
            insights = analysis_result.get('integrated_insights', {})
            risk_score = insights.get('combined_risk_score', 0.0)
            threat_count = insights.get('threat_signatures_count', 0)

            # Criterios para creaciÃ³n automÃ¡tica de incidentes
            if risk_score >= 0.7 or threat_count >= 2:
                incident_data = {
                    'incident_id': f"AUTO-{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                    'title': f"Automated Threat Detection - Risk Score: {risk_score:.2f}",
                    'severity': self._calculate_incident_severity(risk_score),
                    'description': f"Automatically created incident based on MLE-STAR analysis. {threat_count} threat signatures detected.",
                    'source': 'mle_star_integration',
                    'analysis_reference': analysis_result.get('analysis_id'),
                    'risk_score': risk_score,
                    'threat_count': threat_count,
                    'recommendations': insights.get('recommendations', [])
                }

                # Agregar a cola de incidentes
                await self.incident_queue.put(incident_data)

                logger.info(f"Incidente automÃ¡tico creado: {incident_data['incident_id']}")

        except Exception as e:
            logger.error(f"Error creando incidente automÃ¡tico: {e}")

    def _calculate_incident_severity(self, risk_score: float) -> str:
        """Calcular severidad del incidente basado en score de riesgo"""
        if risk_score >= 0.9:
            return "critical"
        elif risk_score >= 0.7:
            return "high"
        elif risk_score >= 0.4:
            return "medium"
        else:
            return "low"

    async def analyze_with_mle_star(
        self,
        data: Dict[str, Any],
        analysis_type: str = "enterprise",
        hrm_context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """Interfaz principal para anÃ¡lisis con MLE-STAR"""
        try:
            analysis_request = {
                'request_id': f"API-{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                'data': data,
                'analysis_type': analysis_type,
                'hrm_context': hrm_context or {},
                'timestamp': datetime.now().isoformat()
            }

            # Agregar a cola de anÃ¡lisis
            await self.analysis_queue.put(analysis_request)

            # Para esta interfaz, esperar resultado (simplificado para demo)
            await asyncio.sleep(2)  # Simular tiempo de procesamiento

            # En implementaciÃ³n real, usarÃ­amos un mecanismo de callback o polling
            return {
                'status': 'queued',
                'request_id': analysis_request['request_id'],
                'estimated_completion': (datetime.now() + timedelta(seconds=30)).isoformat()
            }

        except Exception as e:
            logger.error(f"Error en anÃ¡lisis MLE-STAR: {e}")
            return {
                'status': 'error',
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }

    async def get_integration_status(self) -> Dict[str, Any]:
        """Obtener estado de la integraciÃ³n"""
        try:
            # Estado de componentes
            component_status = {
                'mle_engine': 'active' if self.mle_engine else 'inactive',
                'hrm_bridge': 'active' if self.hrm_bridge else 'inactive',
                'evolution_system': 'active' if self.evolution_system else 'inactive',
                'industrial_monitor': 'active' if self.industrial_monitor else 'inactive',
                'mcp_client': 'active' if self.mcp_client else 'inactive'
            }

            # Estado de conectores
            connector_status = {
                name: 'active' for name in self.data_connectors.keys()
            }

            # MÃ©tricas de rendimiento
            current_metrics = await self._get_current_system_metrics()

            # Colas de procesamiento
            queue_status = {
                'analysis_queue_size': self.analysis_queue.qsize(),
                'incident_queue_size': self.incident_queue.qsize(),
                'active_integrations': len(self.active_integrations)
            }

            return {
                'integration_status': self.integration_status,
                'component_status': component_status,
                'connector_status': connector_status,
                'queue_status': queue_status,
                'performance_metrics': current_metrics,
                'configuration': {
                    'mle_star_enabled': self.integration_config.mle_star_enabled,
                    'hrm_collaboration_enabled': self.integration_config.hrm_collaboration_enabled,
                    'capability_evolution_enabled': self.integration_config.capability_evolution_enabled,
                    'real_time_analysis': self.integration_config.real_time_analysis
                },
                'uptime': self._calculate_uptime(),
                'last_updated': datetime.now().isoformat()
            }

        except Exception as e:
            logger.error(f"Error obteniendo estado de integraciÃ³n: {e}")
            return {
                'integration_status': 'error',
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }

    async def _get_current_system_metrics(self) -> SystemMetrics:
        """Obtener mÃ©tricas actuales del sistema"""
        try:
            # Estado de componentes MLE-STAR
            mle_status = 'active' if self.mle_engine else 'inactive'
            hrm_status = 'active' if self.hrm_bridge else 'inactive'
            evolution_status = 'active' if self.evolution_system else 'inactive'

            # Contadores
            total_analyses = len(self.performance_metrics)
            active_collaborations = len(self.active_integrations)

            # MÃ©tricas de rendimiento simuladas
            system_performance_score = 0.85  # En implementaciÃ³n real se calcularÃ­a

            resource_utilization = {
                'cpu': 0.45,
                'memory': 0.60,
                'disk': 0.30,
                'network': 0.25
            }

            metrics = SystemMetrics(
                timestamp=datetime.now().isoformat(),
                mle_star_status=mle_status,
                hrm_bridge_status=hrm_status,
                evolution_system_status=evolution_status,
                total_analyses=total_analyses,
                active_collaborations=active_collaborations,
                capability_improvements=0,  # Se calcularÃ­a desde evolution_system
                system_performance_score=system_performance_score,
                resource_utilization=resource_utilization
            )

            return metrics

        except Exception as e:
            logger.error(f"Error obteniendo mÃ©tricas del sistema: {e}")
            return SystemMetrics(
                timestamp=datetime.now().isoformat(),
                mle_star_status='error',
                hrm_bridge_status='error',
                evolution_system_status='error',
                total_analyses=0,
                active_collaborations=0,
                capability_improvements=0,
                system_performance_score=0.0,
                resource_utilization={}
            )

    def _calculate_uptime(self) -> float:
        """Calcular tiempo de actividad del sistema"""
        # Simplificado para demo
        return 3600.0  # 1 hora

# Conectores de datos especializados
class EnterpriseDataConnector:
    """Conector de datos para anÃ¡lisis enterprise"""

    def __init__(self, mle_engine: MLESTAREngine, hrm_bridge: HRMMLECollaborativeBridge):
        self.mle_engine = mle_engine
        self.hrm_bridge = hrm_bridge

    async def process_enterprise_data(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Procesar datos enterprise con MLE-STAR"""
        try:
            # AnÃ¡lisis MLE-STAR
            mle_result = await self.mle_engine.analyze_threat_data(data)

            # ColaboraciÃ³n HRM si estÃ¡ disponible
            if self.hrm_bridge:
                hrm_context = data.get('business_context', {})
                collaboration_result = await self.hrm_bridge.collaborative_threat_analysis(
                    data, hrm_context
                )
                return {
                    'mle_result': asdict(mle_result),
                    'collaboration_result': asdict(collaboration_result),
                    'processing_timestamp': datetime.now().isoformat()
                }

            return {
                'mle_result': asdict(mle_result),
                'processing_timestamp': datetime.now().isoformat()
            }

        except Exception as e:
            logger.error(f"Error en conector enterprise: {e}")
            return {'error': str(e)}

class IndustrialDataConnector:
    """Conector de datos para anÃ¡lisis industrial"""

    def __init__(self, industrial_monitor: Any, mle_engine: MLESTAREngine):
        self.industrial_monitor = industrial_monitor
        self.mle_engine = mle_engine

    async def process_industrial_data(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Procesar datos industriales con MLE-STAR"""
        try:
            # AnÃ¡lisis MLE-STAR adaptado para datos industriales
            mle_result = await self.mle_engine.analyze_threat_data(data)

            # Agregar contexto industrial especÃ­fico
            industrial_context = self._extract_industrial_context(data)

            return {
                'mle_result': asdict(mle_result),
                'industrial_context': industrial_context,
                'isa_iec_compliance': self._check_isa_iec_compliance(mle_result),
                'processing_timestamp': datetime.now().isoformat()
            }

        except Exception as e:
            logger.error(f"Error en conector industrial: {e}")
            return {'error': str(e)}

    def _extract_industrial_context(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Extraer contexto industrial especÃ­fico"""
        return {
            'plc_count': len(data.get('industrial', {}).get('plc_devices', [])),
            'protocol_violations': len(data.get('industrial', {}).get('protocol_violations', [])),
            'safety_alerts': data.get('industrial', {}).get('safety_alerts', 0),
            'production_impact': 'unknown'  # Se calcularÃ­a en implementaciÃ³n real
        }

    def _check_isa_iec_compliance(self, mle_result: MLEAnalysisResult) -> Dict[str, Any]:
        """Verificar cumplimiento ISA/IEC"""
        return {
            'isa_95_compliant': True,  # Simulado
            'iec_62443_compliant': True,  # Simulado
            'compliance_score': 0.95,
            'recommendations': [
                'Review security zones configuration',
                'Update safety system documentation'
            ]
        }

class CentralServerConnector:
    """Conector para servidor central MCP"""

    def __init__(self, mcp_client: Any, mle_engine: MLESTAREngine, hrm_bridge: HRMMLECollaborativeBridge):
        self.mcp_client = mcp_client
        self.mle_engine = mle_engine
        self.hrm_bridge = hrm_bridge

    async def sync_with_central_server(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Sincronizar con servidor central"""
        try:
            # Enviar resultados MLE-STAR al servidor central
            sync_result = {
                'sync_timestamp': datetime.now().isoformat(),
                'data_type': 'mle_star_analysis',
                'payload': data,
                'status': 'synced'
            }

            return sync_result

        except Exception as e:
            logger.error(f"Error sincronizando con servidor central: {e}")
            return {'error': str(e), 'status': 'failed'}

# FunciÃ³n principal de demostraciÃ³n
async def main():
    """DemostraciÃ³n de integraciÃ³n MLE-STAR con SmartCompute"""
    print("ğŸ”— Iniciando IntegraciÃ³n SmartCompute MLE-STAR...")

    # Inicializar integraciÃ³n
    integration = SmartComputeMLESTARIntegration()
    await integration.initialize_integration()

    print("âœ… IntegraciÃ³n inicializada correctamente")

    # Datos de prueba para anÃ¡lisis enterprise
    enterprise_data = {
        "timestamp": datetime.now().isoformat(),
        "source": "enterprise_workstation",
        "network": {
            "connection_count": 180,
            "suspicious_ips": ["203.0.113.42"],
            "bandwidth_usage": 0.78
        },
        "processes": {
            "suspicious_processes": ["cryptominer.exe"],
            "cpu_usage": 0.92,
            "memory_usage": 0.75
        },
        "authentication": {
            "failed_logins": 8,
            "privilege_changes": 1
        },
        "business_context": {
            "department": "finance",
            "criticality": "high",
            "user_type": "admin"
        }
    }

    # Datos de prueba para anÃ¡lisis industrial
    industrial_data = {
        "timestamp": datetime.now().isoformat(),
        "source": "industrial_plc",
        "industrial": {
            "plc_devices": ["192.168.1.100", "192.168.1.101"],
            "protocol_violations": ["modbus_tcp_timeout"],
            "safety_alerts": 1,
            "sensor_anomalies": 2
        },
        "network": {
            "connection_count": 25,
            "protocol_traffic": {
                "modbus_tcp": 150,
                "profinet": 89
            }
        }
    }

    print("\nğŸ” Ejecutando anÃ¡lisis enterprise con MLE-STAR...")
    enterprise_result = await integration.analyze_with_mle_star(
        enterprise_data,
        "enterprise",
        enterprise_data.get("business_context")
    )

    print(f"ğŸ“Š Resultado Enterprise:")
    print(f"  Status: {enterprise_result.get('status')}")
    print(f"  Request ID: {enterprise_result.get('request_id')}")

    print("\nğŸ­ Ejecutando anÃ¡lisis industrial con MLE-STAR...")
    industrial_result = await integration.analyze_with_mle_star(
        industrial_data,
        "industrial"
    )

    print(f"ğŸ“Š Resultado Industrial:")
    print(f"  Status: {industrial_result.get('status')}")
    print(f"  Request ID: {industrial_result.get('request_id')}")

    # Obtener estado de integraciÃ³n
    print("\nğŸ“ˆ Estado de IntegraciÃ³n:")
    status = await integration.get_integration_status()

    print(f"  Estado General: {status['integration_status']}")
    print(f"  Uptime: {status['uptime']:.0f} segundos")

    print(f"\nğŸ”§ Estado de Componentes:")
    for component, state in status['component_status'].items():
        print(f"    {component}: {state}")

    print(f"\nğŸ“Š Estado de Colas:")
    queue_status = status['queue_status']
    print(f"    Cola de anÃ¡lisis: {queue_status['analysis_queue_size']}")
    print(f"    Cola de incidentes: {queue_status['incident_queue_size']}")
    print(f"    Integraciones activas: {queue_status['active_integrations']}")

    print(f"\nâš™ï¸  ConfiguraciÃ³n:")
    config = status['configuration']
    print(f"    MLE-STAR habilitado: {config['mle_star_enabled']}")
    print(f"    ColaboraciÃ³n HRM habilitada: {config['hrm_collaboration_enabled']}")
    print(f"    EvoluciÃ³n de capacidades: {config['capability_evolution_enabled']}")
    print(f"    AnÃ¡lisis en tiempo real: {config['real_time_analysis']}")

    # Simular procesamiento durante un tiempo
    print(f"\nâ³ Simulando procesamiento durante 10 segundos...")
    await asyncio.sleep(10)

    # Mostrar mÃ©tricas finales
    final_status = await integration.get_integration_status()
    print(f"\nğŸ“ˆ MÃ©tricas Finales:")
    print(f"  Estado: {final_status['integration_status']}")
    print(f"  Ãšltima actualizaciÃ³n: {final_status['last_updated']}")

    print("\nğŸ‰ DemostraciÃ³n de integraciÃ³n MLE-STAR completada exitosamente!")
    print("\nğŸ“ CaracterÃ­sticas Integradas:")
    print("  âœ… AnÃ¡lisis colaborativo HRM + MLE-STAR")
    print("  âœ… EvoluciÃ³n adaptativa de capacidades")
    print("  âœ… CreaciÃ³n automÃ¡tica de incidentes")
    print("  âœ… FusiÃ³n de inteligencia en tiempo real")
    print("  âœ… Conectores especializados (Enterprise/Industrial)")
    print("  âœ… SincronizaciÃ³n con servidor central MCP")
    print("  âœ… Monitoreo de rendimiento integrado")
    print("  âœ… OptimizaciÃ³n continua de recursos")

if __name__ == "__main__":
    asyncio.run(main())